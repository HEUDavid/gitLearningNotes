Tensorflow笔记


安装tensorflow-gpu
0.安装依赖
sudo apt-get install g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev

1.安装显卡驱动(也可以直接在cuda中安装显卡驱动)
sudo add-apt-repository ppa:graphics-drivers/ppa
ubuntu-drivers devices
sudo apt install nvidia-430
安装完成重启并可以使用nvidia-smi查看

2.安装 CUDA
sudo sh cuda_10.0.130_410.48_linux.run
需要运行两次 安装文件

===========
= Summary =
===========

Driver:   Installed
Toolkit:  Installed in /usr/local/cuda-10.0
Samples:  Installed in /root

Please make sure that
 -   PATH includes /usr/local/cuda-10.0/bin
 -   LD_LIBRARY_PATH includes /usr/local/cuda-10.0/lib64, or, add /usr/local/cuda-10.0/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-10.0/bin
To uninstall the NVIDIA Driver, run nvidia-uninstall

Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-10.0/doc/pdf for detailed information on setting up CUDA.

Logfile is /tmp/cuda_install_2106.log

3.环境变量
vim ~/.bashrc
# 环境变量

export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
source ~/.bashrc

cuda10安装到这里
4.安装cudnn
sudo dpkg -i libcudnn7_7.4.2.24-1+cuda10.0_amd64.deb
sudo dpkg -i libcudnn7-dev_7.4.2.24-1+cuda10.0_amd64.deb
sudo dpkg -i libcudnn7-doc_7.4.2.24-1+cuda10.0_amd64.deb

测试 cuda
cd /usr/local/cuda-10.1/samples/1_Utilities/deviceQuery
sudo make　　＃编译deviceQuery.cpp文件，生成deviceQuery可执行文件
./deviceQuery
出现Result = PASS 说明安装完成

测试 cudnn
cp -r /usr/src/cudnn_samples_v7/ $HOME
cd $HOME/cudnn_samples_v7/mnistCUDNN
make clean && make
./mnistCUDNN

5.安装tensorflow-gpu

tensor 张量：多维数组 列表 表示数据
阶：张量的维度
    0阶标量
    1阶向量
    2阶矩阵
    n阶张量

计算图Graph=>神经网络
import tensorflow as tf
x = tf.constant([1.0, 2.0])
w = tf.constant([3.0, 4.0])
y = tf.matmul(x, w)
print y
Tensor("matmul:0", shape(1,1), dtype=float32) 节点名：第0个输出 形状 类型

会话Session=>执行计算图 节点运算=>优化线上的权重 参数=>得到模型
with tf.Session() as sess:
    print sess.run(y)

参数 线上的权重 变量 随机给初值
w = tf.Variable(tf.random_normal([2, 3], stddev=2, mean=0, seed=1))
                tf.random_uniform()
                tf.truncated_normal() 去掉过大偏离点的正态分布

tf.zeros([3, 2], int32)
tf.ones([3, 2], int32)
tf.fill([3, 2], 6)
tf.constant([3, 2, 1])

NN实现过程：
    1、准备数据集，提取特征，作为输入为给NN
    2、搭建NN结构，从输入到输出 先搭建计算图，后用会话执行
        NN前向传播算法，计算输出
    3、大量特征数据喂给NN，迭代优化参数
        NN反向传播算法，优化参数训练模型
        每一次的输出与标准答案的差反向传给神经网络，调整参数，直到模型达到要求
    4、使用训练好的模型预测和分类

输入不是计算层 计算层从输入后开始算

变量初始化：在sess.run函数中用tf.global_variables_initializer()
    init_op = tf.global_variables_initializer()
    sess.run(init_op)
计算图节点运算：
    sess.run(y)
用tf.placeholder占位：
喂一组数据：
    x = tf.placeholder(tf.float32, shape=(1, 2))
    sess.run(y, feed_dict={x:[[0.5,0.6]]})
喂多组数据：
    x = tf.placeholder(tf.float32, shape=(None, 2))
    sess.run(y, feed_dict={x:[[0.1, 0.2], [0.2, 0.3], [0.4, 0.5]]})

反向传播 训练参数模型，在所有参数上用梯度下降，使NN模型在训练数据上的损失函数最小
损失函数loss 预测值y与已知答案y_的差距
均方误差MSE 有偏估计的均方误差准则
    MSE(y_, y)=Sigma(y-y_)**2/n
    loss = tf.reduce_mean(tf.square(y_-y))



